{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from label_processor import LabelProcessorSimplified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df2 = pickle.load(open(\"data/df2.pickle\",\"rb\"))\n",
    "labelizer = torch.load(\"/data/data/saved/labelizer.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b2c0d15b923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"find tokens\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtoken_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[\\[|\\{]+\\w+[\\]|\\}]+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"find tokens\")\n",
    "token_lambda = lambda a: re.findall(\"[\\[|\\{]+\\w+[\\]|\\}]+\",a) if type(a)==str else np.nan\n",
    "a = df2.message.progress_apply(token_lambda)\n",
    "a = a.progress_apply(lambda a:a if type(a) == list and len(a) > 0 else np.nan).dropna()\n",
    "b = [i for j in a for i in j]\n",
    "b = pd.Series(b).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Add extra tokens\n",
    "def add_extra_tokens():\n",
    "    from spacy.attrs import ORTH, NORM\n",
    "    for i,j in b.items():\n",
    "        if j>100:\n",
    "            nlp.tokenizer.add_special_case(i,[{ORTH:i}])\n",
    "add_extra_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def tokenize_to_ids(s):\n",
    "    s = nlp(s)\n",
    "    return [i.lex_id if i.lex_id!=0 else i.string for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def chunks(l, n:int):\n",
    "    n = math.ceil(l/n)\n",
    "    def a():\n",
    "        for i in range(0,l,n):\n",
    "            yield (i, i+n)\n",
    "    return list(a())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "upto = max([int(re.findall(\"chunk_(\\d+)\",i)[0]) \\\n",
    "            for i in os.listdir(\"saved/word2vec/tokenized_messages/\") if \"chunk\" in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412a9a81e60f45d09118584a880259c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,(start, end) in enumerate(tqdm(chunks(df2.message.shape[0],1000))):\n",
    "    if i < upto:\n",
    "        continue\n",
    "    if i % 10 == 0:\n",
    "        del nlp\n",
    "        nlp = spacy.load(\"en_core_web_lg\")\n",
    "        add_extra_tokens()\n",
    "    tokenized_messages = df2.message[start:end].apply(tokenize_to_ids)\n",
    "    tokenized_messages.to_pickle(f\"saved/word2vec/tokenized_messages/chunk_{i}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e3be4a667c4c548e0651ca871161ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_messages_list = [pd.read_pickle(f\"saved/word2vec/tokenized_messages/chunk_{i}.pickle\") for i in trange(1000)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokenized_messages.to_pickle(\"saved/word2vec/tokenized_messages_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b480781ec5943bfb6aad05204eccb78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-6:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-391-b5ac1fc57be9>\", line 2, in tokenize_to_ids\n",
      "    s = nlp(s)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/spacy/language.py\", line 439, in __call__\n",
      "    doc = proc(doc, **component_cfg.get(name, {}))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"pipes.pyx\", line 396, in spacy.pipeline.pipes.Tagger.__call__\n",
      "  File \"<ipython-input-391-b5ac1fc57be9>\", line 2, in tokenize_to_ids\n",
      "    s = nlp(s)\n",
      "  File \"<ipython-input-391-b5ac1fc57be9>\", line 2, in tokenize_to_ids\n",
      "    s = nlp(s)\n",
      "  File \"pipes.pyx\", line 415, in spacy.pipeline.pipes.Tagger.predict\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/spacy/language.py\", line 439, in __call__\n",
      "    doc = proc(doc, **component_cfg.get(name, {}))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/spacy/language.py\", line 439, in __call__\n",
      "    doc = proc(doc, **component_cfg.get(name, {}))\n",
      "  File \"nn_parser.pyx\", line 232, in spacy.syntax.nn_parser.Parser.__call__\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"nn_parser.pyx\", line 273, in spacy.syntax.nn_parser.Parser.predict\n",
      "  File \"nn_parser.pyx\", line 286, in spacy.syntax.nn_parser.Parser.greedy_parse\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 131, in predict\n",
      "    y, _ = self.begin_update(X, drop=None)\n",
      "  File \"_parser_model.pyx\", line 243, in spacy.syntax._parser_model.ParserModel.begin_update\n",
      "  File \"_parser_model.pyx\", line 293, in spacy.syntax._parser_model.ParserStepModel.__init__\n",
      "  File \"pipes.pyx\", line 396, in spacy.pipeline.pipes.Tagger.__call__\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 46, in begin_update\n",
      "    X, inc_layer_grad = layer.begin_update(X, drop=drop)\n",
      "  File \"pipes.pyx\", line 415, in spacy.pipeline.pipes.Tagger.predict\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 310, in predict\n",
      "    X = layer(layer.ops.flatten(seqs_in, pad=pad))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 295, in begin_update\n",
      "    X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad), drop=drop)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 46, in begin_update\n",
      "    X, inc_layer_grad = layer.begin_update(X, drop=drop)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 375, in uniqued_fwd\n",
      "    uniq_keys, ind, inv, counts = numpy.unique(\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"<ipython-input-391-b5ac1fc57be9>\", line 2, in tokenize_to_ids\n",
      "    s = nlp(s)\n",
      "  File \"<__array_function__ internals>\", line 5, in unique\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/resnet.py\", line 18, in predict\n",
      "    Y = self._layers[0](X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 263, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/spacy/language.py\", line 439, in __call__\n",
      "    doc = proc(doc, **component_cfg.get(name, {}))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 321, in _unique1d\n",
      "    imask = np.cumsum(mask) - 1\n",
      "  File \"pipes.pyx\", line 396, in spacy.pipeline.pipes.Tagger.__call__\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"pipes.pyx\", line 415, in spacy.pipeline.pipes.Tagger.predict\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 310, in predict\n",
      "    X = layer(layer.ops.flatten(seqs_in, pad=pad))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py\", line 54, in predict\n",
      "    X = self.child.predict(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/resnet.py\", line 18, in predict\n",
      "    Y = self._layers[0](X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/layernorm.py\", line 54, in predict\n",
      "    X = self.child.predict(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/maxout.py\", line 67, in predict\n",
      "    X__BOP += self.b.reshape((self.nO * self.nP,))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/maxout.py\", line 66, in predict\n",
      "    X__BOP = self.ops.gemm(X__BI, W, trans2=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 310, in predict\n",
      "    X = layer(layer.ops.flatten(seqs_in, pad=pad))\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/feed_forward.py\", line 40, in predict\n",
      "    X = layer(X)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 167, in __call__\n",
      "    return self.predict(x)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/neural/_classes/model.py\", line 131, in predict\n",
      "    y, _ = self.begin_update(X, drop=None)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/thinc/api.py\", line 375, in uniqued_fwd\n",
      "    uniq_keys, ind, inv, counts = numpy.unique(\n",
      "  File \"<__array_function__ internals>\", line 5, in unique\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 263, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/numpy/lib/arraysetops.py\", line 315, in _unique1d\n",
      "    mask[1:] = aux[1:] != aux[:-1]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-395-43ca4e97359c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtokenized_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_to_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"experiments2/spacy_tokenized_messages.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/msc/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    851\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/msc/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "with mp.Pool(4) as pool:\n",
    "    tokenized_messages = list(pool.imap(tokenize_to_ids, tqdm(df2.message)))\n",
    "pickle.dump(tokenized_messages, open(\"saved/word2vec/spacy_tokenized_messages.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokenized_messages = pickle.load(open(\"saved/word2vec/spacy_tokenized_messages\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokenized_messages = pd.read_pickle(\"saved/word2vec/tokenized_messages_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9ec04db04747459d9cb2a8c0987472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_tokens = {i for j in tqdm(tokenized_messages) for i in j}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokens = {i for i in all_tokens if type(i) == int}\n",
    "tokens.add(0)\n",
    "tokens = sorted(tokens)\n",
    "d = {token_id:i for i,token_id in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d538f4481de4abaaa17164921aa4c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "potential_new_tokens = [i for j in tqdm(tokenized_messages) for i in j if type(i) != int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vc = pd.Series(potential_new_tokens).str.strip().value_counts()\n",
    "new_tokens = list(vc[vc>100].index)\n",
    "d2 = {token : i+len(tokens) for i,token in enumerate(new_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def get_new_token(token):\n",
    "    if type(token) == int:\n",
    "        return d[token]\n",
    "    elif type(token) == str:\n",
    "        token = token.strip()\n",
    "        if token in d2:\n",
    "            return d2[token]\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7c1989cc614b3e839383c0e70ad63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "tokenized_messages2 = tokenized_messages.progress_apply(lambda a: [get_new_token(i) for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embedding_weights_word2vec = torch.tensor(nlp.vocab.vectors.data[tokens])\n",
    "embedding_weights_new = torch.randn(len(d2)+3,300)\n",
    "embedding_weights = torch.cat([embedding_weights_word2vec,embedding_weights_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokenized_messages2.to_pickle(\"saved/word2vec/tokenized_messagess2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tokenized_messages2 = pd.read_pickle(\"saved/word2vec/tokenized_messagess2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "torch.save(embedding_weights, \"saved/word2vec/word2vec_weights_big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df2 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df2['tokenized_message'] = tokenized_messages2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df2.to_pickle(\"saved/word2vec/df_word2vec_tokenized_big.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "embedding_weights = torch.load(\"saved/word2vec/word2vec_weights_big\")\n",
    "\n",
    "SEP_TOKEN = embedding_weights.shape[0]-1\n",
    "START_TOKEN = embedding_weights.shape[0]-2\n",
    "END_TOKEN = embedding_weights.shape[0]-3\n",
    "\n",
    "del embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_pickle(\"saved/word2vec/df_word2vec_tokenized_big.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cc75ffad7342c48ae50790459a4f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b44bcc39ed499d960c56ed6be78226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9279462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df3['token_len'] = df3.tokenized_message.progress_apply(len)\n",
    "d_interaction_id = {j:i for i,j in enumerate(df3.interaction.unique())}\n",
    "\n",
    "tqdm.pandas()\n",
    "df3['speaker_mask'] = df3.progress_apply(lambda a:[d_interaction_id[a.interaction]]*(a.token_len + 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df3.to_pickle(\"saved/word2vec/df_word2vec_tokenized_big.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_pickle(\"saved/word2vec/df_word2vec_tokenized_big.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def join_lists(*lists, sep):\n",
    "    lists = lists[0].values\n",
    "    def _f(*lists, sep):\n",
    "        for l in lists[:-1]:\n",
    "            yield from l\n",
    "            if sep is not None:\n",
    "                yield sep\n",
    "        yield from lists[-1]\n",
    "    return list(_f(*lists,sep=sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6ec7213e7a4839b00cf54501ef1662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=185486.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "j = partial(join_lists, sep=SEP_TOKEN)\n",
    "conversations_tokenized = df3.groupby('conversation_id').tokenized_message.agg(j)\n",
    "tqdm.pandas()\n",
    "conversations_tokenized = conversations_tokenized.progress_apply(lambda a: [START_TOKEN, *a, END_TOKEN] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df3.drop(['actor_id','timestamp','status','delivery_error'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel.cahn/anaconda3/envs/msc/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd5957506924efebacfafc7e9da4ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=185486.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "j_speaker = partial(join_lists, sep=None)\n",
    "speaker_mask = df3.groupby('conversation_id').speaker_mask.agg(j_speaker)\n",
    "tqdm.pandas()\n",
    "speaker_mask = speaker_mask.progress_apply(lambda a: [*a, 0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "word2vec_df = conversations_tokenized.to_frame().join(speaker_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_df.to_pickle(\"saved/word2vec/word2vec_df_big.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}